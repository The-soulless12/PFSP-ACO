# PFSP-ACO
ImplÃ©mentation en Python de lâ€™algorithme dâ€™optimisation par colonies de fourmis (ACO) pour le problÃ¨me du flowshop de permutations (PFSP), visant Ã  minimiser le makespan Ã  l'aide de la phÃ©romone.

# FonctionnalitÃ©s
- RÃ©solution du PFSP Ã  partir des instances de Taillard.
- Construction probabiliste de solutions basÃ©e sur la phÃ©romone et lâ€™heuristique.
- ArrÃªt de l'algorithme en cas de stagnation : pas dâ€™amÃ©lioration pendant un certain nombre dâ€™itÃ©rations.
- Optimisation automatique des hyperparamÃ¨tres via Optuna (recherche bayÃ©sienne parallÃ¨le).

# Structure du projet
- aco.py : Contient l'implÃ©mentation principale de lâ€™algorithme ACO, la logique de lâ€™optimisation Optuna et la gestion des paramÃ¨tres.
- fonctions.py : Regroupe les fonctions essentielles telles que la lecture et l'analyse des fichiers dâ€™instances ainsi que lâ€™Ã©valuation du makespan pour une combinaison donnÃ©e.
- data/ : RÃ©pertoire contenant les fichiers dâ€™instances du problÃ¨me du flowshop de permutations.

# PrÃ©requis 
- Python version 3.x
- Les blibliothÃ¨ques optuna & numpy.

# Note
- Pour exÃ©cuter le projet, saisissez la commande `python aco.py nom_fichier.txt indice_instance` dans votre terminal.
- Lâ€™algorithme **Ant Colony Optimization (ACO) ğŸœ** sâ€™inspire du comportement collectif des fourmis pour rÃ©soudre des problÃ¨mes dâ€™optimisation. Chaque fourmi virtuelle explore diffÃ©rentes solutions en sâ€™appuyant sur deux Ã©lÃ©ments clÃ©s : les **phÃ©romones** qui servent de mÃ©moire collective pour guider les futures explorations vers de bons chemins et une **fonction heuristique** qui prend en compte des critÃ¨res locaux comme le temps de traitement, pour orienter les choix. Ã€ chaque itÃ©ration, plusieurs solutions sont gÃ©nÃ©rÃ©es. Le meilleur makespan est identifiÃ© et les traces de phÃ©romones sont ajustÃ©es en fonction de la qualitÃ© des solutions obtenues. Ce mÃ©canisme permet de renforcer les bons chemins tout en laissant les moins performants sâ€™estomper. Le processus se poursuit jusquâ€™Ã  ce quâ€™aucune amÃ©lioration ne soit observÃ©e pendant 30 itÃ©rations consÃ©cutives.
- Pour optimiser les performances de lâ€™algorithme, la bibliothÃ¨que **Optuna** a Ã©tÃ© utilisÃ©e. Elle permet dâ€™ajuster automatiquement les paramÃ¨tres de lâ€™ACO (alpha, beta, taux dâ€™Ã©vaporation, Q & le nombre de fourmis) afin dâ€™obtenir une meilleure convergence. Optuna exÃ©cute plusieurs essais en parallÃ¨le, ce qui rÃ©duit le temps de recherche tout en augmentant les chances dâ€™atteindre une solution optimale.
